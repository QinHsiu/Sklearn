{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04cf6eb",
   "metadata": {},
   "source": [
    "### 文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c59837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['character',\n",
       " 'fasnicating',\n",
       " 'is',\n",
       " 'it',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'popular',\n",
       " 'qinhsiu',\n",
       " 'sensation',\n",
       " 'techonology',\n",
       " 'wonderful']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple=[\"Machine learning is fasnicating.it is wonderful!\"\n",
    "       ,\"Machine learning is a sensation techonology.\"\n",
    "       ,\"QinHsiu is a popular character.\"]\n",
    "\n",
    "# 单词计数向量\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec=CountVectorizer()\n",
    "x=vec.fit_transform(simple)\n",
    "x.shape #样本数和单词数目\n",
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64aa9ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>fasnicating</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>popular</th>\n",
       "      <th>qinhsiu</th>\n",
       "      <th>sensation</th>\n",
       "      <th>techonology</th>\n",
       "      <th>wonderful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character  fasnicating  is  it  learning  machine  popular  qinhsiu  \\\n",
       "0          0            1   2   1         1        1        0        0   \n",
       "1          0            0   1   0         1        1        0        0   \n",
       "2          1            0   1   0         0        0        1        1   \n",
       "\n",
       "   sensation  techonology  wonderful  \n",
       "0          0            0          1  \n",
       "1          1            1          0  \n",
       "2          0            0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "CVresult=pd.DataFrame(x.toarray(),columns=vec.get_feature_names())\n",
    "CVresult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c62bc3",
   "metadata": {},
   "source": [
    "##### 句子长的样本对数据影响较大\n",
    "##### 对于一些重复出现较多的单词权重会较大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37270bc3",
   "metadata": {},
   "source": [
    "### 使用TF-IDE进行编码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35f5f7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>fasnicating</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>popular</th>\n",
       "      <th>qinhsiu</th>\n",
       "      <th>sensation</th>\n",
       "      <th>techonology</th>\n",
       "      <th>wonderful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.501310</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534093</td>\n",
       "      <td>0.534093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character  fasnicating        is        it  learning   machine   popular  \\\n",
       "0   0.000000     0.424396  0.501310  0.424396  0.322764  0.322764  0.000000   \n",
       "1   0.000000     0.000000  0.315444  0.000000  0.406192  0.406192  0.000000   \n",
       "2   0.546454     0.000000  0.322745  0.000000  0.000000  0.000000  0.546454   \n",
       "\n",
       "    qinhsiu  sensation  techonology  wonderful  \n",
       "0  0.000000   0.000000     0.000000   0.424396  \n",
       "1  0.000000   0.534093     0.534093   0.000000  \n",
       "2  0.546454   0.000000     0.000000   0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "vec=TFIDF()\n",
    "\n",
    "x=vec.fit_transform(simple)\n",
    "x\n",
    "\n",
    "TFIDFresult=pd.DataFrame(x.toarray(),columns=vec.get_feature_names())\n",
    "TFIDFresult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22278efc",
   "metadata": {},
   "source": [
    "##### 取值为每一个特征在所有句子中所占比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "010df9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character      0.0625\n",
       "fasnicating    0.0625\n",
       "is             0.2500\n",
       "it             0.0625\n",
       "learning       0.1250\n",
       "machine        0.1250\n",
       "popular        0.0625\n",
       "qinhsiu        0.0625\n",
       "sensation      0.0625\n",
       "techonology    0.0625\n",
       "wonderful      0.0625\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算theta\n",
    "CVresult.sum(axis=0)/CVresult.sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5fef5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character      0.083071\n",
       "fasnicating    0.064516\n",
       "is             0.173225\n",
       "it             0.064516\n",
       "learning       0.110815\n",
       "machine        0.110815\n",
       "popular        0.083071\n",
       "qinhsiu        0.083071\n",
       "sensation      0.081192\n",
       "techonology    0.081192\n",
       "wonderful      0.064516\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDFresult.sum(axis=0)/TFIDFresult.sum(axis=0).sum()\n",
    "# 将原本出现次数较多的词，减少其权重\n",
    "# 将原本出现次数较少的词，增加其权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6c84ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索文本数据\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data=fetch_20newsgroups() #加载数据集\n",
    "# 该数据类的参数\n",
    "# subset:选择类中包含的数据子集\n",
    "# categories:目录，选择指定目录的数据\n",
    "# download_if_missing:如果发现本地数据不全是否下载，默认为True\n",
    "# shuffl:打乱样本顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cf3c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55e84609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.sport.hockey',\n",
       " 'sci.space',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "categories=[\"sci.space\" #太空\n",
    "            ,\"rec.sport.hockey\" #曲棍球\n",
    "            ,\"talk.politics.guns\" #枪支问题\n",
    "            ,\"talk.politics.mideast\" #中东问题\n",
    "           ]\n",
    "train=fetch_20newsgroups(subset=\"train\",categories=categories)\n",
    "test=fetch_20newsgroups(subset=\"test\",categories=categories)\n",
    "train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9e0cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: tvartiai@vipunen.hut.fi (Tommi Vartiainen)\n",
      "Subject: Re: Finland/Sweden vs.NHL teams (WAS:Helsinki/Stockholm & NHL expansion)\n",
      "Nntp-Posting-Host: vipunen.hut.fi\n",
      "Organization: Helsinki University of Technology, Finland\n",
      "Lines: 51\n",
      "\n",
      "In <1993Apr16.195754.5476@ousrvr.oulu.fi> mep@phoenix.oulu.fi (Marko Poutiainen) writes:\n",
      "\n",
      ">: FINLAND:  \n",
      ">: \n",
      ">: D-Jyrki Lumme.......20\n",
      ">: D-Teppo Numminen....20\n",
      ">: D-Peter Ahola.......13\n",
      ">: \n",
      ">Well well, they don't like our defenders (mainly Lumme and Numminen)...\n",
      "\n",
      "About 25 is correct for Numminen and Lumme.\n",
      "\n",
      "\n",
      ">: R-Teemu Selanne.....27\n",
      ">: \n",
      ">Compared to Kurri, Selanne's points are too high, lets make it 25 or 26.\n",
      "\n",
      "No, Kurri's points are too low. 27 for Kurri and 28 for Sel{nne.\n",
      "\n",
      ">: well in the Canada Cup and World Championships largely due to the efforts of\n",
      ">: Markus Ketterer (the goalie), 3-4 or the players listed above and luck. There's\n",
      ">: presumably a lot of decent players in Finland that wouldn't be superstars at\n",
      ">: the highest level but still valuable role players, however. My guess would be\n",
      ">: that the Finnish Canada Cup team would be a .500 team in the NHL.\n",
      "\n",
      ">Wow, now, it looks like you don't like our players? What about guys like:\n",
      ">Nieminen, Jutila, Riihijarvi, Varvio, Laukkanen, Makela, Keskinen and (even\n",
      ">if he is aging) Ruotsalainen? The main difference between finnish and North-\n",
      ">American players is, that our players tend to be better in the larger rink.\n",
      ">The Canadian defenders are usually slower that defenders in Europe. \n",
      ">And I think that there was more in our success than Ketterer and luck (though\n",
      ">they helped). I think that the main reason was, that the team worked well\n",
      ">together.\n",
      "\n",
      "\n",
      "That's true. Game is so different here in Europe compared to NHL. North-ame-\n",
      "ricans are better in small rinks and europeans in large rinks. An average\n",
      "european player from Sweden, Finland, Russian or Tsech/Slovakia is a better \n",
      "skater and  puckhandler than his NHL colleague. Especially defenders in NHL\n",
      "are mainly slow and clumsy. Sel{nne has also said that in the Finnish Sm-league\n",
      "game is more based on skill than in NHL. In Finland he couldn't get so many \n",
      "breakaways because defenders here are an average much better skaters than in\n",
      "NHL. Also Alpo Suhonen said that in NHL Sel{nne's speed accentuates because\n",
      "of clumsy defensemen.\n",
      "\n",
      "I have to admit that the best players come from Canada, but those regulars\n",
      "aren't as skilful as regulars in the best european leagues. Also top europeans\n",
      "are in the same level as the best north-americans.(except Lemieux is in the\n",
      "class of his own). \n",
      "\n",
      "Tommi\n",
      "\n",
      "(2303,)\n"
     ]
    }
   ],
   "source": [
    "# 查看文章\n",
    "print(train.data[0])\n",
    "print(train.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dbbdb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.25749023013460703\n",
      "2 0.23708206686930092\n",
      "3 0.24489795918367346\n"
     ]
    }
   ],
   "source": [
    "# 是否存在样本不均衡问题\n",
    "for i in range(1,4):\n",
    "    print(i,(train.target==i).sum()/len(train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9349018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000000</th>\n",
       "      <th>000021</th>\n",
       "      <th>000062david42</th>\n",
       "      <th>000152</th>\n",
       "      <th>000246</th>\n",
       "      <th>000256</th>\n",
       "      <th>...</th>\n",
       "      <th>zwrm</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx6wre</th>\n",
       "      <th>zxp</th>\n",
       "      <th>zxqi</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyg</th>\n",
       "      <th>zz</th>\n",
       "      <th>zz_g9q3</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40725 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00       000  0000  00000  000000  000021  000062david42  000152  000246  \\\n",
       "0  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "1  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "2  0.0  0.058046   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "3  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "4  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "\n",
       "   000256  ...  zwrm   zx  zx6wre  zxp  zxqi   zy  zyg   zz  zz_g9q3  zzzzzz  \n",
       "0     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "1     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "2     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "3     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "4     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 40725 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取数据\n",
    "x_train,x_test,y_train,y_test=train.data,test.data,train.target,test.target\n",
    "tfidf=TFIDF().fit(x_train)\n",
    "x_train_=tfidf.transform(x_train)\n",
    "x_test_=tfidf.transform(x_test)\n",
    "\n",
    "x_train_\n",
    "tosee=pd.DataFrame(x_train_.toarray(),columns=tfidf.get_feature_names())\n",
    "tosee.head() #查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52ce428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "\tBrier under rec.sport.hockey:0.857\n",
      "\tBrier under sci.space:0.033\n",
      "\tBrier under talk.politics.guns:0.169\n",
      "\tBrier under talk.politics.mideast:0.178\n",
      "\tAverage Brier:0.309\n",
      "\tAccuracy:0.975\n",
      "\tTime cost: 00:00:014020\n",
      "\n",
      "\n",
      "ComplementNB\n",
      "\tBrier under rec.sport.hockey:0.804\n",
      "\tBrier under sci.space:0.039\n",
      "\tBrier under talk.politics.guns:0.137\n",
      "\tBrier under talk.politics.mideast:0.160\n",
      "\tAverage Brier:0.285\n",
      "\tAccuracy:0.986\n",
      "\tTime cost: 00:00:016003\n",
      "\n",
      "\n",
      "BernoullisNB\n",
      "\tBrier under rec.sport.hockey:0.925\n",
      "\tBrier under sci.space:0.025\n",
      "\tBrier under talk.politics.guns:0.205\n",
      "\tBrier under talk.politics.mideast:0.193\n",
      "\tAverage Brier:0.337\n",
      "\tAccuracy:0.902\n",
      "\tTime cost: 00:00:027006\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在贝叶斯上进行建模,因为词矩阵为稀疏矩阵，因此放弃高斯朴素贝叶斯\n",
    "from sklearn.naive_bayes import MultinomialNB,ComplementNB,BernoulliNB\n",
    "from sklearn.metrics import brier_score_loss as BS\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "names=[\"MultinomialNB\",\"ComplementNB\",\"BernoullisNB\"]\n",
    "models=[MultinomialNB(),ComplementNB(),BernoulliNB()]\n",
    "\n",
    "for name,clf in zip(names,models):\n",
    "    begin=time()\n",
    "    clf.fit(x_train_,y_train)\n",
    "    y_pred=clf.predict(x_test_)\n",
    "    proba=clf.predict_proba(x_test_)\n",
    "    score=clf.score(x_test_,y_test)\n",
    "    print(name)\n",
    "    \n",
    "    # 对于测试集进行哑变量处理\n",
    "    y_test_=y_test.copy()\n",
    "    y_test_=pd.get_dummies(y_test_)\n",
    "    \n",
    "    # 4个不同的标签取值下的布里尔分数\n",
    "    BSscore=[]\n",
    "    for i in range(len(np.unique(y_train))):\n",
    "        bs=BS(y_test_[i],proba[:,i],pos_label=i)\n",
    "        BSscore.append(bs)\n",
    "        print(\"\\tBrier under {}:{:.3f}\".format(train.target_names[i],bs))\n",
    "    print(\"\\tAverage Brier:{:.3f}\".format(np.mean(BSscore)))\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "    print(\"\\tTime cost:\",datetime.datetime.fromtimestamp(time()-begin).strftime(\"%M:%S:%f\"))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# print(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d05e787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "\tBrier under rec.sport.hockey:0.857\n",
      "\tBrier under sci.space:0.033\n",
      "\tBrier under talk.politics.guns:0.169\n",
      "\tBrier under talk.politics.mideast:0.178\n",
      "\tAverage Brier:0.309\n",
      "\tAccuracy:0.975\n",
      "\tTime cost: 00:00:015012\n",
      "\n",
      "\n",
      "MultinomialNB+Isotonic\n",
      "\tBrier under rec.sport.hockey:0.980\n",
      "\tBrier under sci.space:0.012\n",
      "\tBrier under talk.politics.guns:0.226\n",
      "\tBrier under talk.politics.mideast:0.228\n",
      "\tAverage Brier:0.362\n",
      "\tAccuracy:0.973\n",
      "\tTime cost: 00:00:041009\n",
      "\n",
      "\n",
      "MultinomialNB+Sigmoid\n",
      "\tBrier under rec.sport.hockey:0.968\n",
      "\tBrier under sci.space:0.012\n",
      "\tBrier under talk.politics.guns:0.219\n",
      "\tBrier under talk.politics.mideast:0.222\n",
      "\tAverage Brier:0.355\n",
      "\tAccuracy:0.973\n",
      "\tTime cost: 00:00:053012\n",
      "\n",
      "\n",
      "ComplementNB\n",
      "\tBrier under rec.sport.hockey:0.804\n",
      "\tBrier under sci.space:0.039\n",
      "\tBrier under talk.politics.guns:0.137\n",
      "\tBrier under talk.politics.mideast:0.160\n",
      "\tAverage Brier:0.285\n",
      "\tAccuracy:0.986\n",
      "\tTime cost: 00:00:012002\n",
      "\n",
      "\n",
      "ComplementNB+Isotonic\n",
      "\tBrier under rec.sport.hockey:0.984\n",
      "\tBrier under sci.space:0.007\n",
      "\tBrier under talk.politics.guns:0.227\n",
      "\tBrier under talk.politics.mideast:0.230\n",
      "\tAverage Brier:0.362\n",
      "\tAccuracy:0.985\n",
      "\tTime cost: 00:00:037009\n",
      "\n",
      "\n",
      "ComplementNB+Sigmoid\n",
      "\tBrier under rec.sport.hockey:0.970\n",
      "\tBrier under sci.space:0.009\n",
      "\tBrier under talk.politics.guns:0.217\n",
      "\tBrier under talk.politics.mideast:0.221\n",
      "\tAverage Brier:0.354\n",
      "\tAccuracy:0.986\n",
      "\tTime cost: 00:00:050012\n",
      "\n",
      "\n",
      "BernoullisNB\n",
      "\tBrier under rec.sport.hockey:0.925\n",
      "\tBrier under sci.space:0.025\n",
      "\tBrier under talk.politics.guns:0.205\n",
      "\tBrier under talk.politics.mideast:0.193\n",
      "\tAverage Brier:0.337\n",
      "\tAccuracy:0.902\n",
      "\tTime cost: 00:00:029006\n",
      "\n",
      "\n",
      "BernoulliNB+Isotonic\n",
      "\tBrier under rec.sport.hockey:0.930\n",
      "\tBrier under sci.space:0.017\n",
      "\tBrier under talk.politics.guns:0.181\n",
      "\tBrier under talk.politics.mideast:0.176\n",
      "\tAverage Brier:0.326\n",
      "\tAccuracy:0.937\n",
      "\tTime cost: 00:00:069016\n",
      "\n",
      "\n",
      "BernoulliNB+Sigmoid\n",
      "\tBrier under rec.sport.hockey:0.825\n",
      "\tBrier under sci.space:0.030\n",
      "\tBrier under talk.politics.guns:0.153\n",
      "\tBrier under talk.politics.mideast:0.160\n",
      "\tAverage Brier:0.292\n",
      "\tAccuracy:0.879\n",
      "\tTime cost: 00:00:080019\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在贝叶斯上进行建模,因为词矩阵为稀疏矩阵，因此放弃高斯朴素贝叶斯\n",
    "# 使用校准进行比较\n",
    "from sklearn.naive_bayes import MultinomialNB,ComplementNB,BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV #校准的类\n",
    "from sklearn.metrics import brier_score_loss as BS\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "names=[\"MultinomialNB\"\n",
    "       ,\"MultinomialNB+Isotonic\"\n",
    "       ,\"MultinomialNB+Sigmoid\"\n",
    "       ,\"ComplementNB\"\n",
    "       ,\"ComplementNB+Isotonic\"\n",
    "       ,\"ComplementNB+Sigmoid\"\n",
    "       ,\"BernoullisNB\"\n",
    "      ,\"BernoulliNB+Isotonic\"\n",
    "      ,\"BernoulliNB+Sigmoid\"]\n",
    "models=[MultinomialNB()\n",
    "        ,CalibratedClassifierCV(MultinomialNB(),cv=2,method=\"isotonic\")\n",
    "        ,CalibratedClassifierCV(MultinomialNB(),cv=2,method=\"sigmoid\")\n",
    "        ,ComplementNB()\n",
    "        ,CalibratedClassifierCV(ComplementNB(),cv=2,method=\"isotonic\")\n",
    "        ,CalibratedClassifierCV(ComplementNB(),cv=2,method=\"sigmoid\")\n",
    "        ,BernoulliNB()\n",
    "       ,CalibratedClassifierCV(BernoulliNB(),cv=2,method=\"isotonic\")\n",
    "       ,CalibratedClassifierCV(BernoulliNB(),cv=2,method=\"sigmoid\")]\n",
    "\n",
    "for name,clf in zip(names,models):\n",
    "    begin=time()\n",
    "    clf.fit(x_train_,y_train)\n",
    "    y_pred=clf.predict(x_test_)\n",
    "    proba=clf.predict_proba(x_test_)\n",
    "    score=clf.score(x_test_,y_test)\n",
    "    print(name)\n",
    "    \n",
    "    # 对于测试集进行哑变量处理\n",
    "    y_test_=y_test.copy()\n",
    "    y_test_=pd.get_dummies(y_test_)\n",
    "    \n",
    "    # 4个不同的标签取值下的布里尔分数\n",
    "    BSscore=[]\n",
    "    for i in range(len(np.unique(y_train))):\n",
    "        bs=BS(y_test_[i],proba[:,i],pos_label=i)\n",
    "        BSscore.append(bs)\n",
    "        print(\"\\tBrier under {}:{:.3f}\".format(train.target_names[i],bs))\n",
    "    print(\"\\tAverage Brier:{:.3f}\".format(np.mean(BSscore)))\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "    print(\"\\tTime cost:\",datetime.datetime.fromtimestamp(time()-begin).strftime(\"%M:%S:%f\"))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b3f1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
